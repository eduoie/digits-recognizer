{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b911c9a3-1738-4a13-9b7c-44cebaf856e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122c7895-65fd-4440-95e1-e988c8e6fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/initial_data'\n",
    "\n",
    "SAMPLE_1000 = 'samples_1k_X.npy'\n",
    "SAMPLE_1000_LABELS = 'samples_1k_y.npy'\n",
    "\n",
    "SAMPLE_10K = 'samples_10k_X.npy'\n",
    "SAMPLE_10K_LABELS = 'samples_10k_y.npy'\n",
    "\n",
    "SAMPLE_ALL = 'samples_all_X.npy'\n",
    "SAMPLE_ALL_LABELS = 'samples_all_y.npy'\n",
    "\n",
    "# not realistic, but for the sake of simplicity, just keep it as is\n",
    "TEST_DATA = 'test_X.npy'\n",
    "TEST_DATA_LABELS = 'test_y.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d20b679-f46c-425b-a45c-b444406043e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, SAMPLE_1000), 'rb') as f:\n",
    "    train_data = np.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_DIR, SAMPLE_1000_LABELS), 'rb') as f:\n",
    "    label_data = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214be9bd-7738-44e8-abf3-9ed715fcf4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_data[:900], label_data[:900]\n",
    "valid_X, valid_y = train_data[900:], label_data[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c98b0a-4417-4dfe-ab72-f72259bef4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 28, 28), (900,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaddc898-c307-4e68-9134-12d0ccf138e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGIAAABiCAYAAACrpQYOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPMElEQVR4nO2dW2wbV3rHf2d4EyneSZGWLVJX35Q6juOkdpAgLtDUCIIiWwToYvcpBQrsU4EW6EOD9qGvaR8KFOhTgG6aAkXbAC3QfUgQbIw0aYPETpXYsSxbF0uyRIkiJUu8c4Yz5OmDxFnZlmxdKdriDyBIzoXzzfx5zvm+c74zI6SUtDh4lIM2oMUqLSGahJYQTUJLiCahJUST0BKiSdiVEEKIN4UQo0KICSHEe3tl1GFE7DSOEEJYgDHg94AE8B3wcynlyN6Zd3jYTYn4bWBCSjkppawA/wb8ZG/MOnxYd7HvMWB23fcEcOFxOwghDnsYvySl7NhoxW6EEBsse+RCCyF+AfxiF8d5lri32YrdCJEAYuu+dwHzD28kpfwA+ABaJeJx7KaN+A44LoToFULYgZ8Bv9obsw4fOy4RUkpDCPEnwGeABfillPLWnll2yNix+7qjg7WqpiEp5UsbrWhF1k1CS4gmoSVEk9ASoknYTRzx1COEMF8PL6/VatRqNYQQKIqy4XZSSvNVq9V2ZcszLYQQAovFgs1me+QiAhw9epTe3l4URcFqtWKxWPB4PFitVoaHhxkfH6erq4vnn38ej8dDT08PbW1tpkgzMzPcvXuXxcVFhoeH0TRtx7Y+s0LU/8lWq5W2trYNheju7ubChQtYrVYcDgc2m43Ozk7sdjvVapVkMklfXx+XL1+ms7OTixcv4vf70XWdarXK1atX+fLLLxkfH2dsbOzwCeFwOLBYLGZ1Ybfb8Xg82Gw2vF4vNpsNm82GxWLB6/USjUaxWCyP/E53dzfHjx/HYrFgtVoRQuByuVAUhRMnTpDP5xkcHKS3t5dAIICiKFQqFfL5POVymaWlJdLpNJlM5vBVTUII2tvbcblcphh+v5/+/n7cbjcDAwP4fD7a2tpwOBx0dXVx9uxZrNZHT9VisZgCCSEwDINcLoeqqrz22mv09vbS3d3NuXPnsNls6LpOuVw2L/7k5CTj4+Ok02kMw9jVeT01QtT/+TabjXg8TkdHh/lP9ng8xONx2tvbicVieDwe7HY7DoeDjo4OvF7vhiViI7LZrPlSVZVsNksymUQIQblcRtd15ufnyefzJJNJMpkMpVLp8JQIu91OZ2cnwWCQd999l4sXL5oX22Kx4HA4UBTlgWprfSP8JKSUFItFvvrqKyYmJigWi6iqit1u58qVKxiGQTabRdd1U6RkMkkikcAwjMNXIpxOJ0ePHmVgYIC2tjba2tq2/Bu1Ws10NwEURUFRVkMpKSWGYZBKpZidnaVSqTxwcXVdJ5PJmNVTpVJhZWWFQqGwJ+f31AhRrVbJZrMoikIul6NYLKIoypaFqFQqpFIpNE0zL3I4HCYSiSClpFqtUigUGBkZ4erVq6aLWkdKSaVSoVarYRgGtVqNSqWyZ+f31AhRq9Uol8s4HA5UVUXTNJxO55b3NwyDTCZDsVikVCqh6zpWq5VQKGQKoWkayWSS6enp/TuRTXiiEEKIXwK/D6SllL+1tiwI/DvQA0wDP5VSruyfmZj/wEKhwPDwMA6Hg2g0SiwWQ9d1crkcNpuNwcFBAoGAuZ+maeTzeRYWFvjkk09Ip9Ooqoqu63R2dhKLxfB6vXR1dbGyskKpVNrP09iUrZSIfwL+AfjndcveA65IKd9fy2d6D/iLvTfvN0gpUVWVarXK0NAQ6XSavr4+Tp06RaFQYGZmBrfbTSQSeUCIUqnEwsICo6OjfPzxx0xOTqJpmlk1RaNR4vE4b7zxBpqm7Vmdv12eKISU8ishRM9Di38C/M7a54+A/2afhahTq9XIZDJYrVYURUFKSblcZmFhAY/HQyKRoL29HZ/PR3t7O8VikZmZGebm5igUCmiahq7rZlWXyWSw2+3cvn0bwzAoFouNOI1H2GkbEZVSJgGklEkhRGQPbXos1WqVqakpZmZmuHPnDu3t7eYF9Pv9xGIxFhcXOXv2LCdPnmR+fp7PP/+cRCLBysoKlUrF9JoKhQKlUol0Os34+DhSyqaumnbFfqTT6Lpu9vdUKhWzobVarRQKBQqFwgMeTf3Cr3ddAdMzMgwDVVX30sRts9PxiJQQohNg7T292YZSyg+klC9tNla7GwzDoFwuo2maGSOoqkq5XDZjgEgkwquvvsr58+dxu90bdv41AzsV4lfAu2uf3wX+a2/M2R51t7Pu79eDsnpjLKU0A8BIJILdbjfHFpqNrbiv/8pqwxwWQiSAvwbeBz4WQvwxMAP84X4auVVUVWVoaMj0oILBIBaLhXg8jq7rHD9+HIBUKkU+nz9gax9kK17TzzdZ9bt7bMuu0TSNkZERHA4HJ0+e5OTJk0SjUY4fP06lUiEWi6GqKoVC4ekT4mmiXlXpus7U1BTffvstg4ODxONxHA4HZ86cIRQK4ff7SSaTZntSLBZZWFjYdcfdbnimhIBVj8owDL777jsmJyd58803uXDhAu3t7bz11luoqsro6CipVIp0Os38/DwzMzNkMpkDC+bgGRQCMIO8bDbL4uIiMzMzeDwe2tvbcbvddHR0mMOj9e7zsbExnE4nhULBDPh2O8awHZ5JIWA1WCuXywwNDfHhhx8Si8V45513iEajDA4OAqvub6VSYXJyEofDQSqV4ocffmBpaYlisUi5XG6Yvc+sENVqlWq1SiaTYWpqCoBcLofP58PtdpslQVEUVFUlFothtVqZmpoyOwXrQV4j8oOfWSHqrKyscPPmTebm5tA0jUgkwiuvvEJfX5/Z6ReJRLh8+TKZTAafz8fc3BzXr19ndHSUSqXSkP6nZ16IUqlEqVRieXkZVVXx+/0EAgFcLhd2u51IJILb7WZwcJBCocDy8jJ+v98cqav/xn6XimdeiDr1gSFN0/jmm29IJBL09vZy4sQJOjo6OHPmDDabjb6+PoLBIIZhEAqFmJiY4Ouvv0bX9X2171AJsbS0hKIorKys4HA46O/v5/Tp0zz33HP09/cTCAQ4ffo0tVqNUCjE6dOnuXLlCteuXWsJsdfUajV0XUdKyfLyMolEgkgkQrVaBX6TIeh2uwmHw4RCIQKBAFarlWKxaG631xw6IWA1kaBSqXDv3j3m5+ex2+2Uy2VqtZqZitPR0UEgECCRSHDq1CkWFxeZmJjYt/GKQyNEPSFZURRsNpuZ72SxWMw0y/XUXdtG9dQeGiFsNhuRSASXy0V/fz/RaJRAIEAkEqGnpwefz/dAIlo2myWTyXDv3j3GxsbIZrO7SjJ+Es+8EPU632634/V68Xg8dHd3E4vFOHLkCMeOHSMUCmG32819pJRomkaxWCSfz5v9UPvpwm5lPCLGagbHEaAGfCCl/PuDSKnZDm63G6fTSSQSMROTBwcH8fl8xONxgsEgLpcLj8eD0+k0k5Trk05UVSWXy5ltRzPEEQbw51LK74UQHmBICPFr4I9ocErNdnA6nQSDQfr7+7l06RIdHR289NJL+P1+vF7vphmC9XHtekStqmpzdHGsZWvUMzbyQojbrN4Q5cBSah6m3gDbbDbC4TAul4u+vj66urqIx+OcOnUKj8djCvBwUrKu6+ZFn52dJZ/Pc+fOHe7du8etW7caMk6xrTZiLb/pHHCVA0ypeZh6ar7b7ebll1+ms7OTCxcumFOuIpEIiqI8MLllPaqqMjc3x/379/n000+Znp5mZGSEyclJs4d2389hqxsKIdzAfwB/JqXMbdWt2490mrprabVaTRFisRg+n4++vj6i0ShHjhzB7/ebfUrr7a0nIZdKJYrFIplMhomJCZaXl5mdnWVhYcGc99AotiSEEMLGqgj/IqX8z7XFKSFE51pp2DSlZq/vTlOfXuVwOMwOvIGBAd5++21CoRDd3d14PB5cLhdOp/ORWKBWq5FKpchkMty8eZPvv/+edDrNjRs3KJVK5HI5NE3bV1d1I7biNQngH4HbUsq/W7eqnlLzPvucUrN+rpzVasXr9eJ0OgmFQkSjUY4dO0Z/f7/53eVymfvWx7HrDbBhGCwvL7O0tMTc3Bx3794lnU4zOTlJuVxuSMO84Tk+6cBCiNeA/wFusuq+Avwlq+3Ex0CctZQaKeXyE35r22dZH9IMhUJcunSJcDjMkSNH8Hq9BAIBQqEQPp+Pnp4eHA4HTqfzgcY4n8+TTqdZWVnhxo0bLC8vMzo6SjqdJpVKkUqlKJfLrKys7Fs/0jo2vSnKVrym/2Xju5VBA1JqLBYLdrudQCDA+fPnicfjxGIxAoEAPp+PYDD42P1VVWVpaYlkMsm1a9dIJpPcunXLzNo4yMyN9TRVZK0oCn6/n7a2NmKxGNFoFI/HQzgcJhwO88ILLxAMBvH7/Tidzg1jgXrm39zcHOl0munpaYaGhrh//z4jIyNks1lyuZw566dZaCohrFYrkUgEv9/P66+/zvnz580GuK2tjXA4jM1mA9iwM259XtP4+DjXr19neHiYzz77jHK53LAoeSc0lRAWiwW/32+6n52dnXi9XtxuN3a73YwD6rmt9eSw+oXVdZ1UKkWhUODHH39kbGyMubk5VFU15781owjQZELYbDZOnDjBwMAAL774IufOnTO7q+udd/WJKvl8nunpaSYmJswLnM/n+eKLL0gkEuRyOTNHqVHdFLuhqYQAzOmzuVyOpaWlR6qgarXK4uIi+Xye2dlZZmdnHxAikUiYGRuNiIj3iqa6p1+9jXC5XPj9fjwez4bbaZpGtVo1k8Dq52AYBvfv3zfXN2Ep2Ln72kgMw2B+/pFbxx4KWncwaxJaQjQJLSGahJYQTUJLiCah0V7TElBce3/aCLN7u7s3W9HQOAJACPF/+zHner/Zb7tbVVOT0BKiSTgIIT44gGPuBftqd8PbiBYb06qamoSGCvE0PMlRCBETQnwhhLgthLglhPjTteVBIcSvhRDja++BJ/3Wtlh/x/f9fLH6HKK7QB9gB24Ag406/jbs7AReXPvsYfXpk4PA3wLvrS1/D/ibvTxuI0vEU/EkRyllUkr5/drnPLA+1/ejtc0+Av5gL4/bSCE2epLjsQYef9s8LtcX2NNc30YKsaUnOTYLD+f67vfxGinElp7k2Aw8Ltd3bf1jb5+3ExopxFPxJMct5PrCfuT6NtgjeYtVL+Qu8FcH7SFtYuNrrFaZPwLX115vASHgCjC+9h7cy+O2IusmoRVZNwktIZqElhBNQkuIJqElRJPQEqJJaAnRJLSEaBL+H9ODaHM+B/NiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGIAAABiCAYAAACrpQYOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAK4klEQVR4nO2dy28b1xWHvzMPvoakKJKSQ0uin4JgI3HkwnCbtIsCRYMgmxQBCjgIiiwKZJEWaIFujHbRbdtF/wADDZpF0aJACzS7xggKON0YcRP3oQp17Bq2KSmUKL5f4ut2IXFqK5JNm69xNB9AcDjD4T3kb+6dc849nBGlFC7jRxu3AS7buEI4BFcIh+AK4RBcIRyCK4RD6EsIEXlZRP4jIjdF5OKgjDqIyJPGESKiAzeAbwIp4CPgdaXUvwdn3sGhnx5xHriplPqvUqoB/A54dTBmHTyMPvadAe7d9zoFfPlhO4jIQQ/jM0qpqb029COE7LHucz+0iLwFvNVHO18k7uy3oR8hUsDcfa9ngdXdb1JKXQIugdsjHkY/54iPgHkROSYiHuAC8N5gzDp4PHGPUEq1ROT7wJ8BHXhHKbU0MMsOGE/svj5RY+7Q9Del1Lm9NriRtUNwhXAIrhAOwRXCIfQTRxwYRAQRQdM0RIR2u02n0xloG64QjyAUCjE9PU0sFuPFF1/E7/dz5coVbty4QbVapVKpDKQdV4hHYFkWs7OzHD9+nDfeeIPJyUny+TwbGxsAX0whNE0jHA7j8XgwDANd16lUKuRyOcZV9uP1eolGo4RCIcrlMgDNZhORvVJtT46jhDAMg5mZGSKRCH6/H5/PRyqVolgs0mq1xmKTZVnMzc0Ri8XIZDLkcrmB9YL7cZQQmqYRDAYJh8OEQiECgQD5fH7gR9/j2tQ9KAzDQNOG42g6SgjTNEkmkySTSaLRKOFwGKUU165do9lsjtweESEQCBCPx4nFYsTjcQB8Pt/A23KUEN0eEY1GiUQihMNh/H7/WHpE1101TZNgMEggEMAwDNttbbfbAz1vOUoIr9fL6dOnWVxcpFQqDWUs7pXucJRMJnnhhRfQdZ21tTVyuRyrq6uk02kajcbA2nNUZK3rOs888wxHjx5lYmJirLaYponf7ycej3P8+HEOHz5MvV4nl8tRKBQolUpsbW0NrL1HCiEi74jIuoj86751URG5LCKf7jxPDsKY7hA0zpMzbA+RCwsLvPTSS5w5cwbDMGi325RKJfL5/EB7gt1mD+/5NfDyrnUXgQ+UUvPABzuvB2PQThphnGiaxpkzZ3jttdc4d+4chmHQarXI5/Nks9nxCKGUugJkd61+FXh3Z/ld4Fv9GKHrOpZlEQgE8Pl8eDwedF3v5yP7xjAM22Xt5pe6QtTr9cG394T7HVJKrQEopdZEZLofI3w+H4lEgtnZWdtt9Xq9/Xxk35imic/ns+2o1+vcvHmTGzduUCwWB97e0L2mXsppdF0nGAwSCoXs9Ma4hidN09B1HcMw8Hq96LqOiNDpdKjX61QqlaFE+U8qRFpEEju9IQGs7/fGXsppQqEQp06dIplMEolEME1zLEOTpmkEAgH8fj/RaJR4PE4wGEREaLVaFIvFsZ6s9+I94M2d5TeBP/VjhGmaxGIxotEoXq/XTiMopUaa7BMRvF6vLUYgEMDj8aCUotPpsLW1RbPZHPhcBPTQI0Tkt8DXgbiIpICfAj8Dfi8i3wXuAt/uxwiPx0M0GiUajWKaJgClUol0Ok2xWBzKF98Ln8/H+fPnOXLkCAsLC1iWRbvdJpvNksvlqNVqbG1t0W63B972I4VQSr2+z6ZvDMoI0zSJRCJMTExgmiZKKSqVCpubm5TL5ZH1Cp/Px+LiIs8++ywnTpzAsixKpRKFQoFCoUC9Xh9fjxgX1WqVzc1NSqXSwIXQdR1N07Asi3A4/EBib2FhgWQySSgUAiCXy7G0tMStW7colUo0Go2DI4RSilwux507d8hkMgP/4qZpYpoms7OznDx5kkQiwfnz54lGozz//PPEYjHbbV1dXeXy5cusrKyQyWSo1WoDtaWLI4XoFcMwMIztr9Cd4Pf5fOi6bj+627pBo2EYtos8MzNjp9yDwSB+vx/TNB9wnxuNBvl8nkKhMNTJKccK4fV6sSwLn8+3b0wRCoWYmpqyRfB4PJw4cYKJiQk7dd2NC8LhMIuLi4TDYTRNsx+6rlOv18lms3YE3Wq17DR4qVSye+Yw3NYujhBit5vadSO7M3WhUOhzE0MiwuTkpC0EbKeuZ2ZmmJycJBwOY1mW/YNGIhFOnjxpTzYBtjuqlLJPxK1Wi06nY9vUarUol8tUq9Whem+OEKLT6dBsNmk2m7TbbUSEs2fPEo1GyWazpFKpPV3GqakpDh06ZEe/mqbZ0Xn3da1Wo1Ao0Ol0WFpaot1u295YJpMhnU5TrVZZX19ncnKSt99+m4mJCQzDQClFtVplY2ODfD5/MIamdrttz3qJCLOzs0xPT9tVHHsdjfF4nEQiYQ9N3c9RStn+fqFQsIeYrudz9+5dMpkMKysr3L59m3q9TrFYJJFIcOHCBbuATClFs9kcySSVI4TIZrN8+OGHTE9PIyLMzc3ZmdhGo0G1Wt1zv06nQ61Wo1arsb6+Tr1ep1wu02g0yOVyFItFarUa5XKZra0tNjc32drasisx8vk8xWIRv9/P/Pw8s7OzxGIx/H6/Pf9Qq9VGEsc4Qoj19XXef/99wuEw7Xabo0ePkkwmSSQSD92vW+GxsbHBJ598QqlUYnV1lXK5zL1791hbWwN44IfsLt//HAwGee6555ibm2NqaopAIGDPxFWr1YMjBGwf3Y1Gg5WVFfto/Oyzz3raN5/Pc+fOHarVKplM5rGzpKZp2ikWj8cD/D/FUigUDpYQALVajatXr9pVfr1mYLsiKqXsc8TjnFgty2J+ft4eEpVS3Lt3j+vXr3P79u2h5JZ24yghlFJDi1wfRtdd9ng8dua3Wq2SzWZHlutylBBOodPpkEql+Pjjj7l79+5IeoSjymmcRKVSYX19fWQ9opdymjkR+YuILIvIkoj8YGf9UEpqDiq99IgW8COl1CngK8D3ROQ0QyypOYj0Uk6zppT6eGe5BCyzfUGUgZbUOIVulN7NdQ2j4HgvHuscISJHgbPAVXaV1AB9ldQ4CRGx/7LVzdYOm569JhEJAn8AfqiUKvZa7vK0Xp2mO4cxChGgxx4hIibbIvxGKfXHndXpnVIaHlZSo5S6pJQ6t9+lD5xI10saZW1VL16TAL8ClpVSv7xv00BLapxCVwRN0+wIfxT0MjR9FfgO8E8Rub6z7scMuKTGSYgIsViMY8eO2Wn0YdNLOc1f2ftqZTDAkhqnYVnWA5V+w8aNrHdx/yTTKHGF2IdRi+Em/YBWq0U2m8WyrKFWajwMt0cA5XKZ5eVllpeXqVQqIy9+BrdHANhz3H6/n1QqhcfjIZ1Ok81mbWGGjXtNP7ar0SORCF6vl8OHDxMIBCgWi5TLZYrFIul0elA1Tfte088VYrS4F1d0Oq4QDsEVwiG4QjgEVwiHMOo4IgNUdp6fNuL0b/eR/TaM1H0FEJFrT9MkUZdh2+0OTQ7BFcIhjEOIS2NocxAM1e6RnyNc9sYdmhzCSIV4Gu7kOLZa3+4kyLAfbN+H6BZwHPAAfwdOj6r9x7AzAXxpZznE9t0nTwO/AC7urL8I/HyQ7Y6yRzwVd3IcV63vKIXY606OMyNs/7EZZa3vKIXo6U6OTmF3re+w2xulED3dydEJ9FPr+6SMUoin4k6OY6v1HbFH8grbXsgt4Cfj9pD2sfFrbA+Z/wCu7zxeAWJs/zPq053n6CDbdSNrh+BG1g7BFcIhuEI4BFcIh+AK4RBcIRyCK4RDcIVwCP8Doa3AOv4UunAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3):  \n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.show()\n",
    "    \n",
    "train_y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbdabc-465a-4b11-8b0c-22fd0b0f7696",
   "metadata": {},
   "source": [
    "## Train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c55add-a5bb-4527-93a0-fe34c17e0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32') / 255.0\n",
    "valid_X = valid_X.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a356e3e-6325-4e09-8968-a59b689f7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d531183e-7848-4c4e-aa98-db528fdb87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 12:30:06.595802: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcfd3b21-1bab-4795-8eec-4d253db55f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0406 - accuracy: 0.3211\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4088 - accuracy: 0.7056\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0201 - accuracy: 0.7867\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.8200\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.8267\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8578\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8633\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8589\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8867\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb34816d790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(train_X, train_y, epochs=10, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19030de5-9b0b-40ea-9da2-38d473fa3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5253971815109253, 0.8799999952316284]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_X, valid_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67fc87-b9e2-4294-bfeb-7904e4fec72b",
   "metadata": {},
   "source": [
    "# Log models with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f82396b-e358-4b52-b2c5-e35d7bf2caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0e6e02-cd8c-435c-8daa-e88d0312dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q mlflow[extras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eaa0f6e-fbfa-451f-b016-08dabe8c0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dca885-efce-47fb-b949-089584e9065c",
   "metadata": {},
   "source": [
    "The uri of the server is given at the `docker_compose.yml` file: `container_name: mlflow_server`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81fa049e-960a-4ce6-8eff-920e38e00f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://mlflow_server:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd703d9-87bd-40ef-be03-e36e4ef73cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have been unable to use the MLFlow proxied artifact storage access for scenario 5 :(\n",
    "\n",
    "PROXY_ARTIFACTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ca24b-2d41-4804-b292-01e86f066a0e",
   "metadata": {},
   "source": [
    "The config below requires to setup boto3 and configure credentials for the MLFlow client (this notebook)\n",
    "\n",
    "It represents this scenario: https://www.mlflow.org/docs/latest/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\n",
    "\n",
    "It doesn't require to set up mlflow server with --serve-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97de0f0-6b7c-4090-b5ce-9935817ae8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if not PROXY_ARTIFACTS:\n",
    "    %pip install -q boto3\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "    # mlflow.set_registry_uri('mlflow-artifacts:/')\n",
    "    mlflow.set_experiment(\"simple-keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2de83ec-5955-40f9-8c4b-8bc58c3ab6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if this is correct or not\n",
    "if PROXY_ARTIFACTS:\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "    # mlflow.set_registry_uri('mlflow-artifacts:/')\n",
    "    mlflow.set_experiment(\"simple-keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942e769-ea74-4056-be09-0a105debf870",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "Starting a server with the --serve-artifacts flag enables proxied access for artifacts. The uri mlflow-artifacts:/ replaces an otherwise explicit object store destination (e.g., “s3:/my_bucket/mlartifacts”) for interfacing with artifacts. The client can access artifacts via HTTP requests to the MLflow Tracking Server. This simplifies access requirements for users of the MLflow client, eliminating the need to configure access tokens or username and password environment variables for the underlying object store when writing or retrieving artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb779e8-ea43-4502-a0ec-702795a68bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.keras\n",
    "\n",
    "# Enable auto-logging to MLflow to capture TensorBoard metrics.\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f2df857-7093-4058-872c-a547e23145c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.1446 - accuracy: 0.2667\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4856 - accuracy: 0.6811\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0838 - accuracy: 0.7722\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.8111\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.8267\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.8533\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.8556\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8800\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8867\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8978\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.9056\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.9167\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.9167\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.9300\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 12:31:24.042752: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2z71b7tw/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_artifact(os.path.join(DATA_DIR, SAMPLE_1000))\n",
    "    mlflow.log_artifact(os.path.join(DATA_DIR, SAMPLE_1000_LABELS))\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    # fit the model\n",
    "    model.fit(train_X, train_y, epochs=15, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b27d56e-bc3b-4271-99c6-d3159fc59ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4739953875541687, 0.8999999761581421]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_X, valid_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30bae0c5-5ca0-4424-ab6b-76cd219311d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/10 12:31:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ae1ef212cfa6457493c58a4161b87b40', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.9130 - accuracy: 0.4433 - val_loss: 1.3752 - val_accuracy: 0.7400\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0556 - accuracy: 0.7533 - val_loss: 0.8765 - val_accuracy: 0.8300\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.8267 - val_loss: 0.6996 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.8656 - val_loss: 0.5754 - val_accuracy: 0.8700\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8867 - val_loss: 0.5319 - val_accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8989 - val_loss: 0.4901 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.9189 - val_loss: 0.4911 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.9367 - val_loss: 0.4515 - val_accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.9333 - val_loss: 0.4551 - val_accuracy: 0.9100\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9411 - val_loss: 0.4257 - val_accuracy: 0.9100\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6j8r7crn/model/data/model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2e88bb850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(train_X, train_y, epochs=10, batch_size=64, validation_data=(valid_X, valid_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342df7d0-2127-4384-be41-1e2cc62907c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376c3f3-d37b-448b-8d7f-56e41d7df430",
   "metadata": {},
   "source": [
    "Next model is not recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d977f604-1bbf-4947-bdb0-75a201155f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 2.0456 - accuracy: 0.3411 - val_loss: 1.5998 - val_accuracy: 0.6600\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3257 - accuracy: 0.6444 - val_loss: 0.9685 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.7622 - val_loss: 0.6806 - val_accuracy: 0.8100\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.8144 - val_loss: 0.6001 - val_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8600 - val_loss: 0.4947 - val_accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8822 - val_loss: 0.4750 - val_accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8911 - val_loss: 0.4334 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9067 - val_loss: 0.4413 - val_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.9078 - val_loss: 0.4530 - val_accuracy: 0.9200\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.9244 - val_loss: 0.4310 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c50e5ccd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),    \n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(train_X, train_y, epochs=10, batch_size=64, validation_data=(valid_X, valid_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88c757e1-063b-420b-97ce-d753972d9b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.loss</th>\n",
       "      <th>metrics.val_accuracy</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>metrics.val_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>params.initial_epoch</th>\n",
       "      <th>params.use_multiprocessing</th>\n",
       "      <th>params.validation_freq</th>\n",
       "      <th>params.validation_split</th>\n",
       "      <th>params.opt_name</th>\n",
       "      <th>tags.mlflow.autologging</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.log-model.history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ae1ef212cfa6457493c58a4161b87b40</td>\n",
       "      <td>3</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>s3://digits-recognizer-project/experiments/3/a...</td>\n",
       "      <td>2022-03-10 12:31:38.136000+00:00</td>\n",
       "      <td>2022-03-10 12:31:58.646000+00:00</td>\n",
       "      <td>0.251724</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.941111</td>\n",
       "      <td>0.425701</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>/opt/conda/lib/python3.9/site-packages/ipykern...</td>\n",
       "      <td>jovyan</td>\n",
       "      <td>[{\"run_id\": \"ae1ef212cfa6457493c58a4161b87b40\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107d4c95893241c4a22397f3b7f8b3b0</td>\n",
       "      <td>3</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>s3://digits-recognizer-project/experiments/3/1...</td>\n",
       "      <td>2022-03-10 12:31:13.243000+00:00</td>\n",
       "      <td>2022-03-10 12:31:37.995000+00:00</td>\n",
       "      <td>0.283735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>/opt/conda/lib/python3.9/site-packages/ipykern...</td>\n",
       "      <td>jovyan</td>\n",
       "      <td>[{\"run_id\": \"107d4c95893241c4a22397f3b7f8b3b0\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  ae1ef212cfa6457493c58a4161b87b40             3  FINISHED   \n",
       "1  107d4c95893241c4a22397f3b7f8b3b0             3  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  s3://digits-recognizer-project/experiments/3/a...   \n",
       "1  s3://digits-recognizer-project/experiments/3/1...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2022-03-10 12:31:38.136000+00:00 2022-03-10 12:31:58.646000+00:00   \n",
       "1 2022-03-10 12:31:13.243000+00:00 2022-03-10 12:31:37.995000+00:00   \n",
       "\n",
       "   metrics.loss  metrics.val_accuracy  metrics.accuracy  metrics.val_loss  \\\n",
       "0      0.251724                  0.91          0.941111          0.425701   \n",
       "1      0.283735                   NaN          0.925556               NaN   \n",
       "\n",
       "   ... params.initial_epoch params.use_multiprocessing params.validation_freq  \\\n",
       "0  ...                    0                      False                      1   \n",
       "1  ...                    0                      False                      1   \n",
       "\n",
       "  params.validation_split params.opt_name tags.mlflow.autologging  \\\n",
       "0                     0.0            Adam              tensorflow   \n",
       "1                     0.0            Adam                    None   \n",
       "\n",
       "  tags.mlflow.source.type                            tags.mlflow.source.name  \\\n",
       "0                   LOCAL  /opt/conda/lib/python3.9/site-packages/ipykern...   \n",
       "1                   LOCAL  /opt/conda/lib/python3.9/site-packages/ipykern...   \n",
       "\n",
       "  tags.mlflow.user                      tags.mlflow.log-model.history  \n",
       "0           jovyan  [{\"run_id\": \"ae1ef212cfa6457493c58a4161b87b40\"...  \n",
       "1           jovyan  [{\"run_id\": \"107d4c95893241c4a22397f3b7f8b3b0\"...  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df = mlflow.search_runs(filter_string=\"metrics.accuracy > 0.5\")\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9016ab1f-e0d3-4fef-8ecc-11bec05b6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = runs_df.loc[runs_df['metrics.accuracy'].idxmax()]['run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d8d4314-2780-41d9-9219-7bde6815f6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ae1ef212cfa6457493c58a4161b87b40'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdeba561-9080-4209-bcfd-e8d8393311c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'keras-digits-model-1'.\n",
      "2022/03/10 12:50:14 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: keras-digits-model-1, version 1\n",
      "Created version '1' of model 'keras-digits-model-1'.\n"
     ]
    }
   ],
   "source": [
    "result = mlflow.register_model(\n",
    "    f\"runs:/{run_id}\",\n",
    "    \"keras-digits-model-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db576e43-c160-4a6a-a26e-1fa98da51d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
