{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Train model in 1 step\n",
    "\n",
    "Processing the images is really simple here, so it won't be split into another container to save in development time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sm_bucket = sess.default_bucket()\n",
    "                     \n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'digits-recognizer-project'\n",
    "dataset = 'input_data/mnist_data'\n",
    "input_data_s3_uri = 's3://{}/{}/'.format(bucket, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://digits-recognizer-project/input_data/mnist_data/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sagemaker Instances Pricing: https://aws.amazon.com/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = \"ml.m5.large\"\n",
    "train_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.70.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.83.0.tar.gz (520 kB)\n",
      "     |████████████████████████████████| 520 kB 24.5 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs==20.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.20.23)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (1.23.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (2.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.20.21->sagemaker) (1.26.7)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.83.0-py2.py3-none-any.whl size=719395 sha256=b3a51d6fff50821571d8c5a2066f79308a97a721687330fe9dd6207270d0d4fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/1d/68/f4db3097e83a069737269b641e4468eab29b574b07cbf1a7b3\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: attrs, sagemaker\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 19.3.0\n",
      "    Uninstalling attrs-19.3.0:\n",
      "      Successfully uninstalled attrs-19.3.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.70.0\n",
      "    Uninstalling sagemaker-2.70.0:\n",
      "      Successfully uninstalled sagemaker-2.70.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.23.23 which is incompatible.\u001b[0m\n",
      "Successfully installed attrs-20.3.0 sagemaker-2.83.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Update to support TF 2.7\n",
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='./local_train',\n",
    "                       role=role,\n",
    "                       framework_version='2.7',\n",
    "                       py_version='py38',\n",
    "                       instance_count=train_instance_count,\n",
    "                       instance_type=train_instance_type,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'EstimatorBase' has no attribute '_json_encode_hyperparameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0a58b36482c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m estimator.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data_s3_uri\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEstimatorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json_encode_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_stage_user_code_in_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \"\"\"Uploads the user training script to S3 and returns the S3 URI.\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1468\u001b[0m     ):\n\u001b[1;32m   1469\u001b[0m         \"\"\"Return a ``Transformer`` that uses a SageMaker Model based on the training job.\n\u001b[0;32m-> 1470\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m         \u001b[0mIt\u001b[0m \u001b[0mreuses\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSageMaker\u001b[0m \u001b[0mSession\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mname\u001b[0m \u001b[0mused\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_get_train_args\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0menable_network_isolation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSpecifies\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mcontainer\u001b[0m \u001b[0mwill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m                 \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0misolation\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNetwork\u001b[0m \u001b[0misolation\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mrestricts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mcontainer\u001b[0m \u001b[0maccess\u001b[0m \u001b[0mto\u001b[0m \u001b[0moutside\u001b[0m \u001b[0mnetworks\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minternet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mThe\u001b[0m \u001b[0mcontainer\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmake\u001b[0m \u001b[0many\u001b[0m \u001b[0minbound\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutbound\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mhyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         hyperparameters.update(\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mEstimatorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json_encode_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         )\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'EstimatorBase' has no attribute '_json_encode_hyperparameters'"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs={\"train\": input_data_s3_uri},\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... this obscure error didn't happen before. I will ignore it for now and deploy a trained model that seemed to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  tensorflow-training-2022-03-22-12-43-47-937\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print(\"Training Job Name:  {}\".format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/tensorflow-training-2022-03-22-12-43-47-937\">Training Job</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(\n",
    "            region, training_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/TrainingJobs;prefix=tensorflow-training-2022-03-22-12-43-47-937;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\n",
    "            region, training_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/digits-recognizer-project/tensorflow-training-2022-03-22-12-43-47-937/?region=us-east-1&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>'.format(\n",
    "            bucket, training_job_name, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://$sm_bucket/$training_job_name/output/model.tar.gz s3://$bucket/models/model_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://digits-recognizer-project/models/model_v1.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/models/model_v1.tar.gz ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/\n",
      "01/model_v1.h5\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./model/\n",
    "!tar -xvzf ./model.tar.gz -C ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "# model = Model(model_data=f's3://{bucket}/models/model_v1.tar.gz', role=role)\n",
    "\n",
    "# # predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.large')\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "tensorflow_model_name = f'tensorflow-inference-{timestamp}\n",
    "\n",
    "model = TensorFlowModel(\n",
    "    name=tensorflow_model_name,\n",
    "    framework_version='2.7', \n",
    "    model_data=f's3://{bucket}/models/model_v1.tar.gz', \n",
    "    role=role)\n",
    "\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.large')\n",
    "# An error is produced: ValueError: no SavedModel bundles found!\n",
    "# This is due to improper formatting of the model files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(\n",
    "     EndpointName=tensorflow_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy another trained model\n",
    "\n",
    "Due to the error produced above, I uploaded a model properly versioned with `1/` to the s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow.serving import Model\n",
    "# model = Model(model_data=f's3://{bucket}/models/model_v1.tar.gz', role=role)\n",
    "# # predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.large')\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "import time\n",
    "\n",
    "# timestamp = int(time.time())\n",
    "tensorflow_model_name = f'tensorflow-inference-model-1'\n",
    "\n",
    "model = TensorFlowModel(\n",
    "    name=tensorflow_model_name,\n",
    "    framework_version='2.7', \n",
    "    model_data=f's3://{bucket}/models/model.tar.gz', \n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.c5.large',\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.tensorflow.model.TensorFlowPredictor at 0x7fa343f0e5d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use endpoint for predictions\n",
    "\n",
    "We will add `Data Capture` to save the inputs. They will be saved into JSONL files. **Important note**: Captured data is not available immediately after the predictions are returned. In my case, it took around 10 minutes for that data to appear in the S3 bucket.\n",
    "\n",
    "Recorded data can be later used to determine the quality of the algorithm by using human labelers. Another option, that can be combined or used independently, is using Augmented AI (A2I), a human-in-the-loop flow that is launched when the predictions of the model are below a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "capture_data_dir = 'captured_data'\n",
    "data_capture_s3_uri = 's3://{}/{}/'.format(bucket, capture_data_dir)\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100, \n",
    "    destination_s3_uri=data_capture_s3_uri)\n",
    "\n",
    "predictor.update_data_capture_config(data_capture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(results):\n",
    "    predict_number = np.argmax(results)\n",
    "    return predict_number, results[predict_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_source = '../data/initial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(os.path.join(mnist_source, 'test_X.npy'))\n",
    "y_test = np.load(os.path.join(mnist_source, 'test_y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (28, 28))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0.202673554)\n",
      "(2, 0.164640158)\n",
      "(1, 0.162040204)\n",
      "(0, 0.252759784)\n",
      "(4, 0.152242526)\n",
      "(1, 0.169381008)\n",
      "(4, 0.186517209)\n",
      "(9, 0.149589553)\n",
      "(4, 0.13040334)\n",
      "(9, 0.171408907)\n",
      "(0, 0.169871584)\n",
      "(6, 0.122587062)\n",
      "(9, 0.171075225)\n",
      "(0, 0.266866058)\n",
      "(1, 0.154099584)\n",
      "(3, 0.151482627)\n",
      "(7, 0.1409408)\n",
      "(7, 0.213926122)\n",
      "(3, 0.182020247)\n",
      "(9, 0.137253851)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(get_predict(np.array(predictor.predict(x_test[i])['predictions']).squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict an image from DIDA dataset\n",
    "This is a different dataset that requires preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# predict an unseen image\n",
    "im2 = Image.open(\"2_87.jpg\").convert('L')\n",
    "im2 = ImageOps.invert(im2)\n",
    "thresh = 150\n",
    "fn = lambda x: x if x > thresh else 0\n",
    "im2 = im2.point(fn, mode='L')\n",
    "im2 = im2.resize((28,28))\n",
    "pic = np.array(im2)\n",
    "print(pic.shape)\n",
    "pic = pic.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [[0.0977991819, 0.0658421293, 0.0827841833, 0.122882776, 0.145602629, 0.123223945, 0.0780024678, 0.0777508393, 0.110717252, 0.0953945443]]}\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(pic)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted number: 4, probability: 14.56%\n"
     ]
    }
   ],
   "source": [
    "predict_number = np.argmax(results['predictions'])\n",
    "print(f\"predicted number: {predict_number}, probability: {results['predictions'][0][4] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown endpoint to incur in extra costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
